{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Two:  Context-Free Grammars and Shift-Reduce Parsing\n",
    "\n",
    "Please provide answers to these problems by filling in this notebook and submitting it via websubmit by Tuesday 2/6 by midnight.  For the second problem, you must also submit an electronic version of your drawings, either using drawing software or by scanning or photographing hand drawings. Make sure in the latter case that the result is legible; if we can not understand your drawing, it will receive no credit. \n",
    "\n",
    "You may submit by Wednesday midnight for a 20% penalty; after that no credit will be given. \n",
    "\n",
    "I will drop the lowest homework/lab combination at the end of the term.\n",
    "\n",
    "For coding problems any <i> reasonable </i> solution, in which you understand the spirit of the exercise and try to learn this week's material through your efforts, will be graded based solely on the test cases. In general, shortcuts to avoid learning the material will be unreasonable. For example, you may not use any Python libraries or functions that make your task dramatically easier (e.g., you may use split(), replace(...), int(...), and float(...), as mentioned below, and any other normal functions, but may NOT use the Python library for regular expressions).  Good Python style, using list comprehensions, Numpy, creating helper functions in addition to what is required, etc., <i>when appropriate,</i> are quite reasonable! Check with me if you have questions about this. \n",
    "\n",
    "<b> Make sure to click Cell -> Run All before submitting notebooks!!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem One (10 pts)\n",
    "\n",
    "Give context-free grammars for the following languages. \n",
    "<ol style=\"list-style-type: lower-alpha;\">\n",
    "      <li>The language of matching delimiters over the alphabet: <pre>\n",
    "      {    }    [    ]    (    )        \n",
    "</pre>   \n",
    "   \n",
    "   the following are in the language:  <code>   (())    ({})    {([]())}{}</code> <br>\n",
    "   the following are not:   <code>   ({)}   {{{}})  </code>  $\\epsilon$ (empty string)<br>\n",
    "\n",
    "</li>      \n",
    "      <li> The language $\\{ a^n b^m a^n |\\, n \\ge 0 \\text{ and } m > 1 \\}$\n",
    "      <li> The language represented by the regular expression $a\\, b^\\ast\\, (\\,c\\,|\\,d\\,)$.\n",
    "      <li> The language over $\\{ a,b\\}$ of strings with an odd number of a's and any number of b's. \n",
    "      <li>The language over alphabet $\\{a,b\\}$ where the number of $a$'s = the number of $b$'s (any length, including 0). \n",
    "</ol>\n",
    "Hint: For c and d, the languages are regular: simulate a DFA by associating a non-terminal with each state, and then write rules which make \"transitions\" from one state to another; each rule will have a single non-terminal in the last position on the right-hand side. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "<pre>\n",
    "a) S := (S)\n",
    "   S := {S}\n",
    "   S := [S]\n",
    "   S := SS\n",
    "   S := E\n",
    "   E := e\n",
    "   \n",
    "b) S := TST\n",
    "   T := aT\n",
    "   S := bbF\n",
    "   T := a|e\n",
    "   F := b|e\n",
    "\n",
    "c) S := aT\n",
    "   T := bT|c|d\n",
    " \n",
    "d) S := bS|aT\n",
    "   T := BT|aS\n",
    "   S := a\n",
    "   T := e\n",
    " \n",
    "e) S := aSb|bSa|e\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Two (5 pts)\n",
    "\n",
    "This is a problem showing how difficult it sometimes is to create non-ambiguous grammars for standard programming language constructs. It is called the \"dangling else problem.\"\n",
    "\n",
    "(a) Show that the following obvious grammar for conditional statements is ambiguous by showing\n",
    "two different parse trees for the input <code> if expr then if expr then stmt else stmt</code>.      \n",
    "<pre>   \n",
    "     S := if expr then S\n",
    "     S := if expr then S else S\n",
    "     S := stmt\n",
    "</pre>    \n",
    "\n",
    "(b) Now consider the following, more complicated grammar, which is NOT ambiguous:\n",
    "<pre>\n",
    "    S :=  M\n",
    "    S := U\n",
    "    M := if expr then M else M\n",
    "    M := stmt\n",
    "    U := if expr then S\n",
    "    U := if expr then M else U\n",
    "</pre>\n",
    "(M representes \"matched then's\" and U representes \"unmatched then's.\"\n",
    "Show the parse tree for the dangling-else example from (a) using this new grammar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "<pre>\n",
    "Drawing in a separate file!\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Three (10 pts)\n",
    "\n",
    "For each of the following either give some proof/argument/intuition as to why it is true, or give a counter-example showing it is not true. If it is true, an example may illustrate the intuition, but is not sufficient by itself. \n",
    "\n",
    "<p>Let $G$ be a grammar and $w$ be a string of terminal symbols.\n",
    "\n",
    "<ol style=\"list-style-type: lower-alpha;\">\n",
    "      <li> If each rule in $G$ has most one non-terminal on the right-hand side, then any left-most derivation of a string $w$ is also a right-most derivation. \n",
    "      <li> $G$ is ambiguous if and only if there are two different right-most derivations of some string $w$. \n",
    "      <li> If there are two distinct derivations (of any kind) of $w$ in $G$, then $G$ is ambiguous. \n",
    "      <li> If $G$ is not ambiguous, then every derivation of $w$ in $G$ will have the same number of derivation steps (those indicated by => in the derivations). \n",
    "      <li> If $G$ is ambiguous, then there are an infinite number of strings $w$ each of which has more than one parse tree.  \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "<pre>\n",
    "a)True. If there is at most 1 non terminal on the right side then the parsing tree would be a stright line so the left and right derivation will be the exact same!\n",
    "b)False. G can be ambiguous if there are 2 different parse trees and if there are 2 different left-most derivations so it is not if and only if.\n",
    "c)False. We can use our example from class with int*int+int which have 2 distinct derivations(left and right) and it is not ambiguous.\n",
    "d)True. We can see this is true because when you look at the tree you can see that the lines we draw don't change even with our right and left derivations which means the derivation steps are the same.\n",
    "e)False. My example would be question 2 part a) our input could be stmt, which means that it would only have 1 parse tree.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Four  Parser (20 pts)\n",
    "\n",
    "Here is the grammar similar to the one discussed in lecture for the language of arithmetic expressions (we have added a rule for parenthesized expressions):\n",
    "<pre>\n",
    "0:   S := E $\n",
    "1:   E := E + T\n",
    "2:   E := T\n",
    "3:   T := T * F\n",
    "4:   T := F\n",
    "5:   F := ( E )\n",
    "6:   F := int\n",
    "\n",
    "</pre>\n",
    "\n",
    "In the rest of this problem, you will add code to build a shift-reduce parser for this grammar. The transition table is given, and you have to supply code to complete the parser. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexer Code: Insert your lexer code in this next cell (or use my posted solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Code for lexer\n",
    "\n",
    "# put white space between each token and split into words\n",
    "def split_tokens(s):\n",
    "    for t in ['+','-','*','/','(',')',',']:\n",
    "        s = s.replace(t,' ' + t + ' ')\n",
    "    return s.split()\n",
    "\n",
    "def is_letter(c):\n",
    "    return 'a' <= c <= 'z' or 'A' <= c <= 'Z'\n",
    "\n",
    "def is_digit(c):\n",
    "    return '0' <= c <= '9' \n",
    "\n",
    "# recognizer for identifiers\n",
    "\n",
    "def is_id_token(s):\n",
    "    state = 1\n",
    "    for i in range(len(s)):\n",
    "        if state == 1:\n",
    "            if is_letter(s[i]) or s[i] == '_':\n",
    "                state = 2\n",
    "            else:\n",
    "                state = -1\n",
    "            pass\n",
    "        elif state == 2:\n",
    "            if is_letter(s[i]) or is_digit(s[i]) or s[i] == '_':\n",
    "                state = 2\n",
    "            else:\n",
    "                state = -1\n",
    "    return (state == 2)\n",
    "\n",
    "# recognizer for integer\n",
    "\n",
    "def is_int_token(s):\n",
    "    if s == '0':\n",
    "        return True\n",
    "    state = 1\n",
    "    for i in range(len(s)):\n",
    "        if state == 1:\n",
    "            if is_digit(s[i]) and s[i] != '0':\n",
    "                state = 2\n",
    "            else:\n",
    "                state = -1\n",
    "        elif state == 2:\n",
    "            if is_digit(s[i]):\n",
    "                state = 2\n",
    "            else:\n",
    "                state = -1\n",
    "    return (state == 2)\n",
    "\n",
    "# recognizer for floating-point numbers\n",
    "\n",
    "def is_float_token(s):\n",
    "    state = 1\n",
    "    final_states = [4,6]\n",
    "    for i in range(len(s)):\n",
    "        if state == 1:\n",
    "            if is_digit(s[i]) and s[i] != '0':\n",
    "                state = 2\n",
    "            elif s[i] == '0':\n",
    "                state = 3\n",
    "            elif s[i] == '.':\n",
    "                state = 5\n",
    "            else:\n",
    "                return False\n",
    "        elif state == 2:\n",
    "            if is_digit(s[i]):\n",
    "                state = 2\n",
    "            elif s[i] == '.':\n",
    "                state = 4\n",
    "            else:\n",
    "                return False\n",
    "        elif state == 3:\n",
    "            if s[i] == '.':\n",
    "                state = 4\n",
    "            else:\n",
    "                return False\n",
    "        elif state == 4:\n",
    "            if is_digit(s[i]):\n",
    "                state = 4\n",
    "            else:\n",
    "                return False\n",
    "        elif state == 5:\n",
    "            if is_digit(s[i]):\n",
    "                state = 6\n",
    "            else:\n",
    "                return False\n",
    "        elif state == 6:\n",
    "            if is_digit(s[i]):\n",
    "                state = 6\n",
    "            else:\n",
    "                return False                \n",
    "                \n",
    "    return (state in final_states)   \n",
    "    \n",
    "def is_plus_token(s):\n",
    "    return s == '+'\n",
    "    \n",
    "def is_minus_token(s):\n",
    "    return s == '-'\n",
    "\n",
    "def is_mult_token(s):\n",
    "    return s == '*'\n",
    "    \n",
    "def is_div_token(s):\n",
    "    return s == '/'\n",
    "\n",
    "def is_lparen_token(s):\n",
    "    return s == '('\n",
    "    \n",
    "def is_rparen_token(s):\n",
    "    return s == ')'\n",
    "\n",
    "def is_comma_token(s):\n",
    "    return s == ','\n",
    "\n",
    "# convert strings into tokens, if not possible return error token\n",
    "\n",
    "def string_to_token(s):\n",
    "    if is_id_token(s):\n",
    "        return ((ident,s))\n",
    "    elif is_int_token(s):\n",
    "        return( (integer,int(s)) )\n",
    "    elif is_float_token(s):\n",
    "        return( (floating,float(s)) )\n",
    "    elif is_plus_token(s):\n",
    "        return( (plus,) )\n",
    "    elif is_minus_token(s):\n",
    "        return( (minus,) )\n",
    "    elif is_mult_token(s):\n",
    "        return( (mult,) )\n",
    "    elif is_div_token(s):\n",
    "        return( (div,) )\n",
    "    elif is_lparen_token(s):\n",
    "        return( (lparen,) )\n",
    "    elif is_rparen_token(s):\n",
    "        return( (rparen,) )\n",
    "    elif is_comma_token(s):\n",
    "        return( (comma,) )\n",
    "    else:\n",
    "        return( (error,) ) \n",
    "\n",
    "def lexer(input_string):\n",
    "    return [string_to_token(s) for s in split_tokens(input_string)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Code (do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The symbols of the\n",
    "# terminals are encoded by pairs (category,etc) according to:\n",
    "\n",
    "ident = 0           # not used in this hw, but leave it in for the future!\n",
    "integer = 1\n",
    "floating = 2        # not used in this hw\n",
    "plus = 3\n",
    "minus = 4           # not used in this hw\n",
    "mult = 5\n",
    "div = 6             # not used in this hw\n",
    "lparen = 7\n",
    "rparen = 8\n",
    "comma = 9           # not used in this assignment\n",
    "error = 10        \n",
    "\n",
    "# Non-terminals are encoded as pairs using these codes:\n",
    "\n",
    "S = 11             # these will be represented as tuples, e.g., (S,), just like terminals\n",
    "E = 12\n",
    "T = 13\n",
    "F = 14\n",
    "\n",
    "# special token for end of input\n",
    "\n",
    "end_of_input = 15       # (end_of_input,) will be pretty-printed as ($,)\n",
    "\n",
    "\n",
    "# pretty-printing lists of tokens\n",
    "\n",
    "tokenCats = ['ident','integer','floating','plus','minus','mult','div',\n",
    "             'lparen','rparen','comma','error','S','E','T','F','$']\n",
    "\n",
    "def tokenToString(t):\n",
    "    if t == None:\n",
    "        return str(t)\n",
    "    elif t[0] < 3:\n",
    "        return '(' + tokenCats[t[0]] + ',' + str(t[1]) + ')'\n",
    "    else:\n",
    "        return '(' + tokenCats[t[0]] + ',)'\n",
    "        \n",
    "def tokenListToString(lst):\n",
    "    res = '[ '\n",
    "    for t in lst[:-1]:\n",
    "        res = res + tokenToString(t) + ', '\n",
    "    res = res + tokenToString(lst[-1]) + ' ]'\n",
    "    return res\n",
    "\n",
    "# pretty-printing parser configurations\n",
    "\n",
    "def pprintParser(parsingStack,inputListOfTokens):\n",
    "    totalWidth = 80\n",
    "    smallestGap = 6\n",
    "    largestStackLength = int(totalWidth*0.6 - smallestGap/2)   # most characters to display\n",
    "    largestInputLength = totalWidth - largestStackLength - smallestGap\n",
    "    \n",
    "    p = '| '\n",
    "    for symbol in parsingStack:\n",
    "        p = p + tokenToString(symbol) + ' '\n",
    "    if len(p) > largestStackLength:\n",
    "        ind = int(len(p) - largestStackLength + 9)\n",
    "        p = '| ... ' + p[ind:]\n",
    "        \n",
    "    q = \"\"\n",
    "    for tok in inputListOfTokens[:-1]:\n",
    "        q = q + tokenToString(tok) + ' '\n",
    "    if len(inputListOfTokens) > 0:\n",
    "        q = q + tokenToString(inputListOfTokens[-1]) \n",
    "\n",
    "    if len(q) > largestInputLength:\n",
    "        ind = int(largestInputLength - 9)\n",
    "        q = q[:ind] + ' ... ' \n",
    "    \n",
    "    q = q + ' |'\n",
    "        \n",
    "    p = p + (' ' * (totalWidth - len(p) - len(q)))\n",
    "    print(p+q)\n",
    "\n",
    "# pretty-printing rules\n",
    "\n",
    "def toStringRule(r):\n",
    "    s = tokenCats[r[0][0]] + ' := '\n",
    "    for t in r[1]:\n",
    "        s = s + tokenCats[t[0]] + ' '\n",
    "    return s\n",
    "                          \n",
    "def toStringRules(lst): \n",
    "    s = \"\"\n",
    "    for r in lst:\n",
    "        s = s + toStringRule(r) + '\\n'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (A): Encoding the rules\n",
    "\n",
    "Rules will be represented by pairs (lhs, rhs) where lhs is a single non-terminal tuple\n",
    "and rhs is a list of tuples for terminals or non-terminals. For example, the start\n",
    "rule would be represented as follows:\n",
    "<pre>\n",
    "((S,),[(E,),(end_of_input,)])\n",
    "</pre>\n",
    "In the next cell, encode the list of rules in the order given above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar:\n",
      "\n",
      "S := E $ \n",
      "E := E plus T \n",
      "E := T \n",
      "T := T mult F \n",
      "T := F \n",
      "F := lparen E rparen \n",
      "F := integer \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rules = [((S,),[(E,),(end_of_input,)]), ((E,), [(E,),(plus,),(T,)]), ((E,),[(T,)]), ((T,),[(T,),(mult,),(F,)]), ((T,),[(F,)]), ((F,),[(lparen,), (E,), (rparen,)]), ((F,),[(integer,)])]                    \n",
    "\n",
    "\n",
    "\n",
    "print(\"Grammar:\\n\\n\" + toStringRules(rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Implement the DFA\n",
    "\n",
    "<p> Here is a diagram of the DFA which will be used to read the stack and decide \n",
    "when to do reduce moves. The error state (numbered -100) is implicit. \n",
    "\n",
    "![DFA](http://www.cs.bu.edu/fac/snyder/cs320/Homeworks/HW02Diagram.jpg \"DFA\")\n",
    "\n",
    "We have provided the DFA in the next cell in the form of a transition table. You must complete the definition of the action to be taken when the DFA is applied to the parsing stack plus the \"lookahead\" symbol (next symbol in the input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# transition table   DO NOT MODIFY UNLESS YOU REALLY KNOW WHAT YOU ARE DOING!\n",
    "\n",
    "# special actions used by the parser\n",
    "\n",
    "err = -100\n",
    "accept = 100\n",
    "\n",
    "table = { 1: { 1:6, 2:err, 3:err, 4:err, 5:err, 6:err, 7:9, 8:err, 9:err, 10:err, 11:err, 12:2, 13:4, 14:13, 15:err}, \n",
    "          2: { 1:err, 2:err, 3:8, 4:err, 5:err, 6:err, 7:err, 8:err, 9:err, 10:err, 11:err, 12:err, 13:err, 14:err, 15:accept}, \n",
    "          3: { 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0, 12:0, 13:0, 14:0, 15:0}, \n",
    "          4: { 1:-2, 2:-2, 3:-2, 4:-2, 5:5, 6:-2, 7:-2, 8:-2, 9:-2, 10:-2, 11:-2, 12:-2, 13:-2, 14:-2, 15:-2}, \n",
    "          5: { 1:6, 2:err, 3:err, 4:err, 5:err, 6:err, 7:9, 8:err, 9:err, 10:err, 11:err, 12:err, 13:err, 14:12, 15:err}, \n",
    "          6: { 1:-6, 2:-6, 3:-6, 4:-6, 5:-6, 6:-6, 7:-6, 8:-6, 9:-6, 10:-6, 11:-6, 12:-6, 13:-6, 14:-6, 15:-6}, \n",
    "          7: { 1:-1, 2:-1, 3:-1, 4:-1, 5:5, 6:-1, 7:-1, 8:-1, 9:-1, 10:-1, 11:-1, 12:-1, 13:-1, 14:-1, 15:-1}, \n",
    "          8: { 1:6, 2:err, 3:err, 4:err, 5:err, 6:err, 7:9, 8:err, 9:err, 10:err, 11:err, 12:err, 13:7, 14:13, 15:err}, \n",
    "          9: { 1:6, 2:err, 3:err, 4:err, 5:err, 6:err, 7:9, 8:err, 9:err, 10:err, 11:err, 12:10, 13:4, 14:13, 15:err}, \n",
    "         10: { 1:err, 2:err, 3:8, 4:err, 5:err, 6:err, 7:err, 8:11, 9:err, 10:err, 11:err, 12:err, 13:err, 14:err, 15:err}, \n",
    "         11: { 1:-5, 2:-5, 3:-5, 4:-5, 5:-5, 6:-5, 7:-5, 8:-5, 9:-5, 10:-5, 11:-5, 12:-5, 13:-5, 14:-5, 15:-5},\n",
    "         12: { 1:-3, 2:-3, 3:-3, 4:-3, 5:-3, 6:-3, 7:-3, 8:-3, 9:-3, 10:-3, 11:-3, 12:-3, 13:-3, 14:-3, 15:-3},\n",
    "         13: { 1:-4, 2:-4, 3:-4, 4:-4, 5:-4, 6:-4, 7:-4, 8:-4, 9:-4, 10:-4, 11:-4, 12:-4, 13:-4, 14:-4, 15:-4}}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this reads a list of tokens (i.e., the parsing stack) and returns the state where you end up\n",
    "\n",
    "def action(lst,table):\n",
    "    state = 1;\n",
    "    for i in lst:\n",
    "        if(state != err  and state != accept):\n",
    "            state = table[state][i[0]];\n",
    "        elif(state == err):\n",
    "            return err;\n",
    "        elif(state == accept):\n",
    "            return accept;\n",
    "        else:\n",
    "            pass\n",
    "    return state;\n",
    "            \n",
    "\n",
    "\n",
    "# TESTS\n",
    "# You may not modify the following in any way\n",
    "# All tests should return True\n",
    "\n",
    "print(action([(lparen,)],table)==9)\n",
    "print(action([(E,),(plus,), (F,)],table) == 13)\n",
    "print(action([(error,),(E,)],table) == err)\n",
    "print(action([(lparen,),(lparen,),(lparen,),(lparen,)],table)== 9)\n",
    "print(action([(lparen,),(lparen,),(E,),(rparen,),(plus,)],table) == -5)\n",
    "print(action([(E,),(end_of_input,)],table) == accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Implement the driver for the parser\n",
    "\n",
    "Most of this has been done, just complete where you see pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# parse takes a list of tokens and determines if it is a \n",
    "# well-formed arithmetic expression.\n",
    "\n",
    "def parse(list_of_input_tokens,rules,table,verbose=False):\n",
    "    \n",
    "    # add end_of_input marker to input\n",
    "    #list_of_input_tokens[-1:] = (end_of_input,);\n",
    "    list_of_input_tokens.append((end_of_input,))\n",
    "    \n",
    "    # input stack; use pop(0) to remove front item in list\n",
    "    input_stack = list_of_input_tokens\n",
    "    \n",
    "    # parsing stack; use append to push onto end and pop() to pop from end\n",
    "    parsing_stack = []\n",
    "    \n",
    "    if verbose:\n",
    "        print('Input Tokens: ' + tokenListToString(input_stack) + '\\n')\n",
    "        pprintParser(parsing_stack,input_stack) \n",
    "    \n",
    "    while( len(input_stack) > 0 ):\n",
    "        \n",
    "        # Now we will \"lookahead\" at the next symbol on the input and ask the automaton what to do\n",
    "        # a positive number means to shift, and a negative number -n means to reduce by rule n\n",
    "        \n",
    "        # complete this next line by calling action on the parsing stack plus the\n",
    "        # next symbol on the input\n",
    "        \n",
    "        n = action(parsing_stack+[input_stack[0]], table);\n",
    "        if n == accept:   # reduce by start rule, success\n",
    "            if verbose:\n",
    "                pprintParser(parsing_stack,input_stack)\n",
    "            return True\n",
    "        elif n == err:     #  problem on stack!\n",
    "            if verbose:\n",
    "                pprintParser(parsing_stack,input_stack)\n",
    "            return False \n",
    "        elif n > 0:     # shift          \n",
    "            left = input_stack.pop(0);\n",
    "            parsing_stack.append(left);        \n",
    "        else:         # reduce by rule -n            \n",
    "            for i in range(len(rules[-n][1])):\n",
    "                parsing_stack.pop();\n",
    "            parsing_stack.append(rules[-n][0]); \n",
    "   \n",
    "        if verbose:\n",
    "            pprintParser(parsing_stack,input_stack)\n",
    "            \n",
    "    return None     # this will never be executed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parser Tests \n",
    "\n",
    "Last two are incorrect and will return False, rest are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: [ (integer,2), ($,) ]\n",
      "\n",
      "|                                                             (integer,2) ($,) |\n",
      "| (integer,2)                                                             ($,) |\n",
      "| (F,)                                                                    ($,) |\n",
      "| (T,)                                                                    ($,) |\n",
      "| (E,)                                                                    ($,) |\n",
      "| (E,)                                                                    ($,) |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 1: Correct parse\n",
    "\n",
    "s = '2'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: [ (lparen,), (integer,2), (plus,), (integer,4), (rparen,), ($,) ]\n",
      "\n",
      "|                                                    (lparen,) (integer,2 ...  |\n",
      "| (lparen,)                                          (integer,2) (plus,)  ...  |\n",
      "| (lparen,) (integer,2)                              (plus,) (integer,4)  ...  |\n",
      "| (lparen,) (F,)                                     (plus,) (integer,4)  ...  |\n",
      "| (lparen,) (T,)                                     (plus,) (integer,4)  ...  |\n",
      "| (lparen,) (E,)                                     (plus,) (integer,4)  ...  |\n",
      "| (lparen,) (E,) (plus,)                            (integer,4) (rparen,) ($,) |\n",
      "| (lparen,) (E,) (plus,) (integer,4)                            (rparen,) ($,) |\n",
      "| (lparen,) (E,) (plus,) (F,)                                   (rparen,) ($,) |\n",
      "| (lparen,) (E,) (plus,) (T,)                                   (rparen,) ($,) |\n",
      "| (lparen,) (E,)                                                (rparen,) ($,) |\n",
      "| (lparen,) (E,) (rparen,)                                                ($,) |\n",
      "| (F,)                                                                    ($,) |\n",
      "| (T,)                                                                    ($,) |\n",
      "| (E,)                                                                    ($,) |\n",
      "| (E,)                                                                    ($,) |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '(2 + 4)'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: [ (integer,2), (plus,), (integer,4), (mult,), (integer,8), (plus,), (integer,5), ($,) ]\n",
      "\n",
      "|                                                    (integer,2) (plus,)  ...  |\n",
      "| (integer,2)                                        (plus,) (integer,4)  ...  |\n",
      "| (F,)                                               (plus,) (integer,4)  ...  |\n",
      "| (T,)                                               (plus,) (integer,4)  ...  |\n",
      "| (E,)                                               (plus,) (integer,4)  ...  |\n",
      "| (E,) (plus,)                                       (integer,4) (mult,)  ...  |\n",
      "| (E,) (plus,) (integer,4)                           (mult,) (integer,8)  ...  |\n",
      "| (E,) (plus,) (F,)                                  (mult,) (integer,8)  ...  |\n",
      "| (E,) (plus,) (T,)                                  (mult,) (integer,8)  ...  |\n",
      "| (E,) (plus,) (T,) (mult,)                          (integer,8) (plus,)  ...  |\n",
      "| (E,) (plus,) (T,) (mult,) (integer,8)               (plus,) (integer,5) ($,) |\n",
      "| (E,) (plus,) (T,) (mult,) (F,)                      (plus,) (integer,5) ($,) |\n",
      "| (E,) (plus,) (T,)                                   (plus,) (integer,5) ($,) |\n",
      "| (E,)                                                (plus,) (integer,5) ($,) |\n",
      "| (E,) (plus,)                                                (integer,5) ($,) |\n",
      "| (E,) (plus,) (integer,5)                                                ($,) |\n",
      "| (E,) (plus,) (F,)                                                       ($,) |\n",
      "| (E,) (plus,) (T,)                                                       ($,) |\n",
      "| (E,)                                                                    ($,) |\n",
      "| (E,)                                                                    ($,) |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '2+4*8+5'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: [ (lparen,), (lparen,), (integer,2), (plus,), (lparen,), (integer,4), (rparen,), (rparen,), (plus,), (integer,4), (rparen,), ($,) ]\n",
      "\n",
      "|                                                    (lparen,) (lparen,)  ...  |\n",
      "| (lparen,)                                          (lparen,) (integer,2 ...  |\n",
      "| (lparen,) (lparen,)                                (integer,2) (plus,)  ...  |\n",
      "| (lparen,) (lparen,) (integer,2)                    (plus,) (lparen,) (i ...  |\n",
      "| (lparen,) (lparen,) (F,)                           (plus,) (lparen,) (i ...  |\n",
      "| (lparen,) (lparen,) (T,)                           (plus,) (lparen,) (i ...  |\n",
      "| (lparen,) (lparen,) (E,)                           (plus,) (lparen,) (i ...  |\n",
      "| (lparen,) (lparen,) (E,) (plus,)                   (lparen,) (integer,4 ...  |\n",
      "| (lparen,) (lparen,) (E,) (plus,) (lparen,)         (integer,4) (rparen, ...  |\n",
      "| ...  (E,) (plus,) (lparen,) (integer,4)            (rparen,) (rparen,)  ...  |\n",
      "| ... paren,) (E,) (plus,) (lparen,) (F,)            (rparen,) (rparen,)  ...  |\n",
      "| ... paren,) (E,) (plus,) (lparen,) (T,)            (rparen,) (rparen,)  ...  |\n",
      "| ... paren,) (E,) (plus,) (lparen,) (E,)            (rparen,) (rparen,)  ...  |\n",
      "| ... ,) (plus,) (lparen,) (E,) (rparen,)            (rparen,) (plus,) (i ...  |\n",
      "| (lparen,) (lparen,) (E,) (plus,) (F,)              (rparen,) (plus,) (i ...  |\n",
      "| (lparen,) (lparen,) (E,) (plus,) (T,)              (rparen,) (plus,) (i ...  |\n",
      "| (lparen,) (lparen,) (E,)                           (rparen,) (plus,) (i ...  |\n",
      "| (lparen,) (lparen,) (E,) (rparen,)                 (plus,) (integer,4)  ...  |\n",
      "| (lparen,) (F,)                                     (plus,) (integer,4)  ...  |\n",
      "| (lparen,) (T,)                                     (plus,) (integer,4)  ...  |\n",
      "| (lparen,) (E,)                                     (plus,) (integer,4)  ...  |\n",
      "| (lparen,) (E,) (plus,)                            (integer,4) (rparen,) ($,) |\n",
      "| (lparen,) (E,) (plus,) (integer,4)                            (rparen,) ($,) |\n",
      "| (lparen,) (E,) (plus,) (F,)                                   (rparen,) ($,) |\n",
      "| (lparen,) (E,) (plus,) (T,)                                   (rparen,) ($,) |\n",
      "| (lparen,) (E,)                                                (rparen,) ($,) |\n",
      "| (lparen,) (E,) (rparen,)                                                ($,) |\n",
      "| (F,)                                                                    ($,) |\n",
      "| (T,)                                                                    ($,) |\n",
      "| (E,)                                                                    ($,) |\n",
      "| (E,)                                                                    ($,) |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '((2 + (4)) + 4)'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: [ (integer,2), (mult,), (integer,5), (plus,), (integer,2), (mult,), (integer,2), (plus,), (integer,4), ($,) ]\n",
      "\n",
      "|                                                    (integer,2) (mult,)  ...  |\n",
      "| (integer,2)                                        (mult,) (integer,5)  ...  |\n",
      "| (F,)                                               (mult,) (integer,5)  ...  |\n",
      "| (T,)                                               (mult,) (integer,5)  ...  |\n",
      "| (T,) (mult,)                                       (integer,5) (plus,)  ...  |\n",
      "| (T,) (mult,) (integer,5)                           (plus,) (integer,2)  ...  |\n",
      "| (T,) (mult,) (F,)                                  (plus,) (integer,2)  ...  |\n",
      "| (T,)                                               (plus,) (integer,2)  ...  |\n",
      "| (E,)                                               (plus,) (integer,2)  ...  |\n",
      "| (E,) (plus,)                                       (integer,2) (mult,)  ...  |\n",
      "| (E,) (plus,) (integer,2)                           (mult,) (integer,2)  ...  |\n",
      "| (E,) (plus,) (F,)                                  (mult,) (integer,2)  ...  |\n",
      "| (E,) (plus,) (T,)                                  (mult,) (integer,2)  ...  |\n",
      "| (E,) (plus,) (T,) (mult,)                          (integer,2) (plus,)  ...  |\n",
      "| (E,) (plus,) (T,) (mult,) (integer,2)               (plus,) (integer,4) ($,) |\n",
      "| (E,) (plus,) (T,) (mult,) (F,)                      (plus,) (integer,4) ($,) |\n",
      "| (E,) (plus,) (T,)                                   (plus,) (integer,4) ($,) |\n",
      "| (E,)                                                (plus,) (integer,4) ($,) |\n",
      "| (E,) (plus,)                                                (integer,4) ($,) |\n",
      "| (E,) (plus,) (integer,4)                                                ($,) |\n",
      "| (E,) (plus,) (F,)                                                       ($,) |\n",
      "| (E,) (plus,) (T,)                                                       ($,) |\n",
      "| (E,)                                                                    ($,) |\n",
      "| (E,)                                                                    ($,) |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '2 * 5 + 2 * 2 + 4'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: [ (lparen,), (integer,2), (plus,), (rparen,), ($,) ]\n",
      "\n",
      "|                                                    (lparen,) (integer,2 ...  |\n",
      "| (lparen,)                                          (integer,2) (plus,)  ...  |\n",
      "| (lparen,) (integer,2)                                 (plus,) (rparen,) ($,) |\n",
      "| (lparen,) (F,)                                        (plus,) (rparen,) ($,) |\n",
      "| (lparen,) (T,)                                        (plus,) (rparen,) ($,) |\n",
      "| (lparen,) (E,)                                        (plus,) (rparen,) ($,) |\n",
      "| (lparen,) (E,) (plus,)                                        (rparen,) ($,) |\n",
      "| (lparen,) (E,) (plus,)                                        (rparen,) ($,) |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '(2 + )'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: [ (lparen,), (integer,2), (plus,), (floating,4.5), (rparen,), ($,) ]\n",
      "\n",
      "|                                                    (lparen,) (integer,2 ...  |\n",
      "| (lparen,)                                          (integer,2) (plus,)  ...  |\n",
      "| (lparen,) (integer,2)                              (plus,) (floating,4. ...  |\n",
      "| (lparen,) (F,)                                     (plus,) (floating,4. ...  |\n",
      "| (lparen,) (T,)                                     (plus,) (floating,4. ...  |\n",
      "| (lparen,) (E,)                                     (plus,) (floating,4. ...  |\n",
      "| (lparen,) (E,) (plus,)                         (floating,4.5) (rparen,) ($,) |\n",
      "| (lparen,) (E,) (plus,)                         (floating,4.5) (rparen,) ($,) |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '(2 + 4.5)'\n",
    "parse(lexer(s),rules,table,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
